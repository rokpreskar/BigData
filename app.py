import os
import json
import re

import streamlit as st
import pandas as pd
import altair as alt
from transformers import pipeline
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

# ---- Render / low-memory friendliness ----
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["MPLCONFIGDIR"] = "/tmp/matplotlib"

# --- PAGE CONFIGURATION ---
st.set_page_config(
    page_title="Brand Reputation Dashboard 2023",
    page_icon="ðŸ“Š",
    layout="wide",
)

# --- DATA LOADING ---
@st.cache_data
def load_scraped_data():
    """Load the JSON data generated by the scraper."""
    try:
        with open("data/scraped_data.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        st.error("âš ï¸ 'data/scraped_data.json' not found! Please run scraper.py first.")
        return None


# --- SENTIMENT MODEL (HUGGING FACE) ---
@st.cache_resource
def get_sentiment_pipeline():
    """Load HF sentiment pipeline once per app session."""
    return pipeline(
        "sentiment-analysis",
        model="distilbert-base-uncased-finetuned-sst-2-english",
        device=-1,  # CPU only
    )


@st.cache_data
def run_sentiment(texts_tuple):
    """Cached inference. Use tuple input for stable caching."""
    sentiment_pipe = get_sentiment_pipeline()
    return sentiment_pipe(
        list(texts_tuple),
        batch_size=8,
        truncation=True,
        max_length=128,
    )


# --- APP ---
data = load_scraped_data()

st.sidebar.title("ðŸ” Navigation")
st.sidebar.markdown("---")
page = st.sidebar.radio("Select a Section:", ["Products", "Testimonials", "Reviews"])

if not data:
    st.stop()

# ---------------------------
# 1) PRODUCTS
# ---------------------------
if page == "Products":
    st.header("ðŸ“¦ Product Catalog")
    st.write("Overview of all scraped products and their pricing.")

    df_products = pd.DataFrame(data.get("products", []))
    if df_products.empty:
        st.warning("No products found in scraped data.")
        st.stop()

    if "price" in df_products.columns:
        df_products["price"] = pd.to_numeric(df_products["price"], errors="coerce")

    col1, col2 = st.columns(2)
    col1.metric("Total Products", len(df_products))
    if "price" in df_products.columns and df_products["price"].notna().any():
        col2.metric("Avg. Price", f"${df_products['price'].mean():.2f}")
    else:
        col2.metric("Avg. Price", "N/A")

    st.dataframe(df_products, width="stretch")

# ---------------------------
# 2) TESTIMONIALS
# ---------------------------
elif page == "Testimonials":
    st.header("ðŸ’¬ Customer Testimonials")
    st.write("Raw feedback collected from the infinite scroll section.")

    df_testimonials = pd.DataFrame(data.get("testimonials", []))
    if df_testimonials.empty:
        st.warning("No testimonials found in scraped data.")
        st.stop()

    st.dataframe(df_testimonials, width="stretch")

    if "rating" in df_testimonials.columns:
        st.subheader("Rating Distribution")
        st.bar_chart(df_testimonials["rating"].value_counts())
    else:
        st.info("No 'rating' column found for testimonials.")

# ---------------------------
# 3) REVIEWS (FILTER + SENTIMENT + VIZ + WORDCLOUD)
# ---------------------------
elif page == "Reviews":
    st.header("ðŸ“ˆ 2023 Reviews Analysis")
    st.write("Filter reviews by specific months within the year 2023.")

    months = [
        "January", "February", "March", "April", "May", "June",
        "July", "August", "September", "October", "November", "December",
    ]
    selected_month_name = st.select_slider("Select a month in 2023:", options=months)

    df_reviews = pd.DataFrame(data.get("reviews", []))
    if df_reviews.empty:
        st.warning("No reviews found in scraped data.")
        st.stop()

    if "date" not in df_reviews.columns:
        st.error("Reviews data has no 'date' column, cannot filter by month.")
        st.stop()

    df_reviews["date"] = pd.to_datetime(df_reviews["date"], errors="coerce")

    month_index = months.index(selected_month_name) + 1
    filtered_df = df_reviews[
        (df_reviews["date"].dt.month == month_index) &
        (df_reviews["date"].dt.year == 2023)
    ].copy()

    if filtered_df.empty:
        st.warning(f"No reviews were scraped for {selected_month_name} 2023.")
        st.stop()

    st.success(f"Found {len(filtered_df)} reviews for {selected_month_name} 2023.")

    # rating metric (if exists)
    if "rating" in filtered_df.columns:
        filtered_df["rating"] = pd.to_numeric(filtered_df["rating"], errors="coerce")

    show_df = filtered_df.copy()
    show_df["date"] = show_df["date"].dt.strftime("%Y-%m-%d")

    if "rating" in filtered_df.columns and filtered_df["rating"].notna().any():
        avg_rating = filtered_df["rating"].mean()
        st.metric(f"Average Rating for {selected_month_name}", f"{avg_rating:.1f} / 5 â­")
    else:
        st.metric(f"Average Rating for {selected_month_name}", "N/A")

    if "text" not in filtered_df.columns:
        st.error("Reviews data has no 'text' column, cannot run sentiment/word cloud.")
        st.dataframe(show_df, width="stretch")
        st.stop()

    # ---- Controls to avoid loading heavy stuff until user asks (Render friendly) ----
    st.markdown("---")
    st.subheader("Controls (Render-safe)")
    c1, c2 = st.columns(2)
    run_sent = c1.button("Run Sentiment Analysis")
    run_wc = c2.button("Generate Word Cloud")

    # ---- SENTIMENT ANALYSIS (only when clicked) ----
    if run_sent:
        try:
            texts = filtered_df["text"].fillna("").astype(str).str.strip().tolist()

            # optional safety cap (even if you don't have many reviews)
            MAX_REVIEWS = 200
            if len(texts) > MAX_REVIEWS:
                st.warning(
                    f"Too many reviews ({len(texts)}). Analyzing first {MAX_REVIEWS} to avoid memory issues on Render."
                )
                texts = texts[:MAX_REVIEWS]
                show_df = show_df.head(MAX_REVIEWS).copy()

            with st.spinner("Running sentiment analysis..."):
                results = run_sentiment(tuple(texts))

            show_df["sentiment"] = [
                "Positive" if r["label"] == "POSITIVE" else "Negative"
                for r in results
            ]
            show_df["sentiment_score"] = [float(r["score"]) for r in results]

            st.subheader("Sentiment Analysis (Hugging Face Transformers)")

            m1, m2, m3 = st.columns(3)
            m1.metric("Positive", int((show_df["sentiment"] == "Positive").sum()))
            m2.metric("Negative", int((show_df["sentiment"] == "Negative").sum()))
            m3.metric("Overall Avg Confidence", f"{show_df['sentiment_score'].mean():.2f}")

            st.subheader("Positive vs Negative Reviews (with Avg Confidence Tooltip)")

            summary = (
                show_df.groupby("sentiment", as_index=False)
                .agg(count=("sentiment", "size"), avg_conf=("sentiment_score", "mean"))
            )

            # Force both categories to appear
            summary = (
                summary.set_index("sentiment")
                .reindex(["Positive", "Negative"])
                .reset_index()
            )
            summary["count"] = summary["count"].fillna(0).astype(int)
            summary["avg_conf"] = summary["avg_conf"].fillna(0.0)

            chart = alt.Chart(summary).mark_bar().encode(
                x=alt.X("sentiment:N", title="Sentiment"),
                y=alt.Y("count:Q", title="Number of Reviews"),
                tooltip=[
                    alt.Tooltip("sentiment:N", title="Sentiment"),
                    alt.Tooltip("count:Q", title="Count"),
                    alt.Tooltip("avg_conf:Q", title="Avg confidence", format=".2f"),
                ],
            )

            text_layer = alt.Chart(summary).mark_text(dy=-10).encode(
                x="sentiment:N",
                y="count:Q",
                text=alt.Text("avg_conf:Q", format=".2f"),
            )

            st.altair_chart(chart + text_layer, width="stretch")

            st.subheader("Reviews Table (with Sentiment)")
            st.dataframe(show_df, width="stretch")

        except Exception as e:
            st.exception(e)
            st.stop()

    # ---- WORD CLOUD (only when clicked) ----
    if run_wc:
        try:
            st.subheader("Word Cloud (Selected Month Reviews)")

            text_blob = " ".join(show_df["text"].fillna("").astype(str)).lower()

            # clean text
            text_blob = re.sub(r"http\S+|www\S+", "", text_blob)
            text_blob = re.sub(r"[^\w\s]", " ", text_blob, flags=re.UNICODE)
            text_blob = re.sub(r"[\d_]+", " ", text_blob)
            text_blob = re.sub(r"\s+", " ", text_blob).strip()

            if len(text_blob) < 20:
                st.info("Not enough text to generate a word cloud.")
            else:
                wc = WordCloud(
                    width=700,
                    height=350,
                    max_words=100,
                    background_color="white",
                    stopwords=set(STOPWORDS),
                    collocations=False,
                ).generate(text_blob)

                fig, ax = plt.subplots(figsize=(10, 4))
                ax.imshow(wc)
                ax.axis("off")
                st.pyplot(fig)

        except Exception as e:
            st.exception(e)
            st.stop()

# --- FOOTER ---
st.sidebar.markdown("---")
st.sidebar.info("Data Mining Homework #3 Rok Preskar")

# Run locally:
# python -m streamlit run app.py
#
# Render start command:
# streamlit run app.py --server.port $PORT --server.address 0.0.0.0
